{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMthzeKb1P4Xhl2Tu8n/hl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbasi07/TF_Specialization_C1/blob/main/text_completion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/keras-team/keras-nlp.git@google-io-2023 tensorflow-text==2.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG8hlOjCEwDW",
        "outputId": "4edf789e-813a-48fa-ceb7-284e3c0a15f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for keras-nlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jTD-QbC2DbZY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "from tensorflow import keras\n",
        "from tensorflow.lite.python import interpreter\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6dsdVAlD2Bo",
        "outputId": "9e49b361-15ea-43d4-afb5-a1dbd52eab7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/vocab.json\n",
            "1042301/1042301 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/merges.txt\n",
            "456318/456318 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length = 256,\n",
        "    add_end_token = True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "3FkxlcOqDvHl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    preprocessor = gpt2_preprocessor\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKOwCWgKHPHM",
        "outputId": "2f3dd91a-c106-4b14-c6e7-604445dae0d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/model.h5\n",
            "497986112/497986112 [==============================] - 9s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'token_embedding/embeddings:0' shape=(50257, 768) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"My trip to Murree was\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output.numpy().decode(\"utf-8\"))\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total time elapsed: \", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh13Q2mlHne2",
        "outputId": "631650c8-15dd-4b3e-ec84-2d86951d78e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "My trip to Murree was a bit of a disappointment. I didn't know what to expect, and I wasn't prepared for it. I was a bit nervous about what I was going to do, and it took a few months to figure out what to expect. It took me a while, but I was ready for it.\n",
            "\n",
            "I've been to many festivals, but I've never been a big fan of music. It's hard to say I've ever really been to one. I'm not going to tell you what I'm going to do. I'm going to tell you what I'm going to do and I'm going to tell you what I'm going to do and what I'm going to do, and it's going to happen. I'm going to do it for the people, and I'm going to do it for myself because that is what this world wants to see.\n",
            "\n",
            "The music that you're going to see on your show, and the music\n",
            "Total time elapsed:  66.39171147346497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"That Italian restuarant is\", max_length=200)\n",
        "print(\"\\nGPT-2 OutputL:\")\n",
        "print(output.numpy().decode(\"utf-8\"))\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total time elapsed: \", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K45TKk84IXrq",
        "outputId": "902426a6-c4e6-4de4-b566-2ca5021675a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 OutputL:\n",
            "That Italian restuarant is a very good option for a good price because it has the same quality and features as the other products, but the price is much lower than the restuarant in the market.\n",
            "\n",
            "I have been a fan of this product for quite some time and I am not sure if there are any other alternatives to this.\n",
            "\n",
            "The rest of the products I have used have been good.\n",
            "\n",
            "I have tried a variety of different products and they all have been good to me. I have also tried a number of other brands, but all of the products that I have used have been very good.\n",
            "\n",
            "The only problem with this product is the price. I have tried it several times and all of them all were very good, but the price of this product is not very good.\n",
            "\n",
            "The price is a bit higher than the rest of the restuarant, but it is not as bad as it should be. It's not as good as the\n",
            "Total time elapsed:  63.23262548446655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"Game of thrones is\", max_length=200)\n",
        "print(\"\\nGPT-2 OutputL:\")\n",
        "print(output.numpy().decode(\"utf-8\"))\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total time elapsed: \", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEbZxNdeJViT",
        "outputId": "c541875e-7c26-4a53-cf15-686ec302b5f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 OutputL:\n",
            "Game of thrones is a game of thrones that is played by a group of players. Players play a variety of different game types and play the game in different ways. Each game consists of four rounds, with the winner of each round having a chance to win. The winner of the first round is chosen at random from among the other players and must be able to win a single round in order to win this round. The winner of the second round is chosen at random from among the other players and must be able to win two rounds in order to win this round.\n",
            "\n",
            "Each round begins with a winner's first choice and continues through to the winner's second choice and the next round with a loser's first choice and the winner of the last round. In the following rounds, the winners are chosen from among those players and the losers must be able to win two rounds in order to win the next round.\n",
            "\n",
            "A player may choose to play a game of one of the following\n",
            "Total time elapsed:  50.87187933921814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.tokenize([\"I am very genius\"]).flat_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb7Voa-yJxRx",
        "outputId": "97dd2a07-0205-4ba8-c246-971d8b283884"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([   40,   716,   845, 15632], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices([\"I am very genius\"])\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHlW20D_Koi8",
        "outputId": "b8941b9a-f91b-4ee9-f62c-a3588f70abe8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_ds = ds.map(gpt2_preprocessor)\n",
        "preprocessed_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvRilZjHK-rS",
        "outputId": "3d138956-0449-448f-fd2b-e06c387b5c65"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'token_ids': TensorSpec(shape=(255,), dtype=tf.int32, name=None), 'padding_mask': TensorSpec(shape=(255,), dtype=tf.bool, name=None)}, TensorSpec(shape=(255,), dtype=tf.int32, name=None), TensorSpec(shape=(255,), dtype=tf.bool, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = next(iter(preprocessed_ds))\n",
        "print('token ids:')\n",
        "print(output[0]['token_ids'])\n",
        "print('padding masks:')\n",
        "print(output[0]['padding_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxezDzs5LLRk",
        "outputId": "9bbd1a2c-4496-423f-de8e-d95ffc32d7d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token ids:\n",
            "tf.Tensor(\n",
            "[   40   716   845 15632 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
            " 50256 50256 50256], shape=(255,), dtype=int32)\n",
            "padding masks:\n",
            "tf.Tensor(\n",
            "[ True  True  True  True  True False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False], shape=(255,), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FDjQRRoLUCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}